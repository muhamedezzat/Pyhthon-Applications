{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "byRJUVrANHlw",
        "wbzPyfj_lS6G",
        "gHIp-Td0xSqm"
      ],
      "authorship_tag": "ABX9TyMqo5SK5XmRANKnc8hRa0y2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhamedezzat/Pyhthon-Applications/blob/master/Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUqVyNDBL_W1"
      },
      "source": [
        "# **Disney Dataset Creation with Python & BeautifulSoup4**\n",
        "\n",
        "Scrape &clean a list of all Disney films from wikipedia pages  to create a dataset for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byRJUVrANHlw"
      },
      "source": [
        "# **Task #1 Get info box data and store it in python dictionary**\n",
        "\n",
        "1) Import Nesecary libraries: \n",
        "\n",
        "**requests** >>>>>> get url link and make request to web page \n",
        "\n",
        "**BeautifulSoup4** >>>>>>>>> Scraping with html pages \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDfMdrk4G5Jq"
      },
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwKlm53sOav8"
      },
      "source": [
        "2) Load web pages Using requests library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSTnjmzDOhCv"
      },
      "source": [
        "r = requests.get(\"https://en.wikipedia.org/wiki/The_Reluctant_Dragon_(1941_film)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cn6TZmKO86D"
      },
      "source": [
        "3) Convert web page to BeautifulSoup Object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8et7PJEpPIoj"
      },
      "source": [
        "soup = bs(r.content)\n",
        "# print out the html \n",
        "contents = soup.prettify()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FizxnmTbQpaL"
      },
      "source": [
        "4) Grapping HTML Objects to deal with its to extract a data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soGxwFl_QoUl"
      },
      "source": [
        "# we use find method to grap HTML object by Selectors \n",
        "# find()：Gets the first tag of the incoming HTML object that satisfies the condition and returns. A function of a label group or a single label.\n",
        "# findAll()：Get all the conditions of the incoming HTML object and return it. Prototype: findAll(tag, atributes, recursive, text, limit, keywords)\n",
        "\n",
        "infoBox = soup.find(class_=\"infobox vevent\")\n",
        "infoRows = infoBox.find_all(\"tr\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24e5Lg2oXUvV"
      },
      "source": [
        "Now I can access to all data in box info \n",
        "\n",
        "Now I need to extract data in form filmee name (title) and their data and stored it in python dictionary \n",
        "\n",
        "`I use Python enumerate() to  adds counter to an iterable and returns it (the enumerate object).`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC88L-GiYNx8",
        "outputId": "9e82b44e-af94-4054-ca26-4b1e144f1271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "movieInfo = { }\n",
        "\n",
        "# get_Conteent_Value to loop in any itam have a list of names and out it in form list not text \n",
        "\n",
        "def get_Content_Value(rowData):\n",
        "  if rowData.find(\"li\"):\n",
        "    return [li.get_text(\" \",strip=True).replace(\"\\xa0\",\" \")  for li in rowData.find_all(\"li\")] \n",
        "  else:\n",
        "    return rowData.get_text(\" \",strip=True).replace(\"\\xa0\",\" \")\n",
        "\n",
        "for index , row in enumerate(infoRows):\n",
        "  if index == 0 :\n",
        "    movieInfo[\"title\"] = row.find(\"th\").get_text(\" \",strip=True)\n",
        "  elif index == 1:\n",
        "    continue\n",
        "  else:\n",
        "    contentKey= row.find(\"th\").get_text(\" \",strip=True)\n",
        "    contentValue= get_Content_Value(row.find(\"td\"))\n",
        "    movieInfo[contentKey] = contentValue\n",
        "\n",
        "for key , value in movieInfo.items():\n",
        "  print(f\"{key} : {value}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title : The Reluctant Dragon\n",
            "Directed by : Alfred Werker (live action) Hamilton Luske (animation) Jack Cutting , Ub Iwerks , Jack Kinney (sequence directors)\n",
            "Produced by : Walt Disney\n",
            "Written by : Live-action: Ted Sears Al Perkins Larry Clemmons Bill Cottrell Harry Clork Robert Benchley The Reluctant Dragon segment: Kenneth Grahame (original book) Erdman Penner T. Hee Baby Weems segment: Joe Grant Dick Huemer John Miller\n",
            "Starring : Robert Benchley Frances Gifford Buddy Pepper Nana Bryant\n",
            "Music by : Frank Churchill Larry Morey\n",
            "Cinematography : Bert Giennon\n",
            "Edited by : Paul Weatherwax\n",
            "Production company : Walt Disney Productions\n",
            "Distributed by : RKO Radio Pictures\n",
            "Release date : ['June 20, 1941 ( 1941-06-20 ) [1]']\n",
            "Running time : 74 minutes\n",
            "Country : United States\n",
            "Language : English\n",
            "Budget : $600,000 [2]\n",
            "Box office : $960,000 (worldwide rentals) [3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbzPyfj_lS6G"
      },
      "source": [
        "# **Task #2 Get info box for all films**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTlE59-JoNZg"
      },
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "def get_Content_Value(rowData):\n",
        "    if rowData.find(\"li\"):\n",
        "      return [li.get_text(\" \",strip=True).replace(\"\\xa0\",\" \")  for li in rowData.find_all(\"li\")] \n",
        "    else:\n",
        "      return rowData.get_text(\" \",strip=True).replace(\"\\xa0\",\" \")\n",
        "\n",
        "\n",
        "def get_All_Films(fullPath):\n",
        "  r = requests.get(fullPath)\n",
        "  soup = bs(r.content)\n",
        "\n",
        "  infoBox = soup.find(class_=\"infobox vevent\")\n",
        "  infoRows = infoBox.find_all(\"tr\")\n",
        "  \n",
        "  movieInfo = {}\n",
        "\n",
        "  for index , row in enumerate(infoRows):\n",
        "    if index == 0 :\n",
        "      movieInfo[\"title\"] = row.find(\"th\").get_text(\" \",strip=True)\n",
        "    elif index == 1:\n",
        "     continue\n",
        "    else:\n",
        "      contentKey= row.find(\"th\").get_text(\" \",strip=True)\n",
        "      contentValue= get_Content_Value(row.find(\"td\"))\n",
        "      movieInfo[contentKey] = contentValue\n",
        "  \n",
        "  return movieInfo\n"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5dptfZHTPCG"
      },
      "source": [
        "allreq = requests.get(\"https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films\")\n",
        "soup2 = bs(allreq.content)\n",
        "filmTables = soup2.select(\".wikitable.sortable i a\")\n",
        "\n",
        "basePath = \"https://en.wikipedia.org/\"\n",
        "\n",
        "movieList = [ ]\n",
        "for index , movie in enumerate(filmTables):\n",
        "  # if index == 2:\n",
        "  #   break\n",
        "\n",
        "  try:\n",
        "    relativePath = movie[\"href\"]\n",
        "    fullPath = basePath + relativePath\n",
        "    title = movie[\"title\"]\n",
        "    movieList.append(get_All_Films(fullPath))\n",
        "  \n",
        "  except Exception as e:\n",
        "      print(movie.get_text())\n",
        "      print(e)\n",
        "\n",
        "# print(movieList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHIp-Td0xSqm"
      },
      "source": [
        "# **Now we are going to save data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7yO_XcxXJmQ"
      },
      "source": [
        "import json\n",
        "def save(title,data):\n",
        "  with open(title,\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump(data,f,ensure_ascii=False,indent=3)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4ZSdjPfyoCS"
      },
      "source": [
        "def load(title):\n",
        "  with open(title,encoding=\"utf-8\") as f:\n",
        "    return json.load(f)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAN0NHBNMus5"
      },
      "source": [
        "save(\"Disney Data.json\",movieList)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}