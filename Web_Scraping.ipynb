{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "byRJUVrANHlw"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNbQfBtfMYMJWjbH8hvhpLw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhamedezzat/Pyhthon-Applications/blob/master/Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUqVyNDBL_W1"
      },
      "source": [
        "# **Disney Dataset Creation with Python & BeautifulSoup4**\n",
        "\n",
        "Scrape &clean a list of all Disney films from wikipedia pages  to create a dataset for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byRJUVrANHlw"
      },
      "source": [
        "# **Task #1 Get info box data and store it in python dictionary**\n",
        "\n",
        "1) Import Nesecary libraries: \n",
        "\n",
        "**requests** >>>>>> get url link and make request to web page \n",
        "\n",
        "**BeautifulSoup4** >>>>>>>>> Scraping with html pages \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDfMdrk4G5Jq"
      },
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwKlm53sOav8"
      },
      "source": [
        "2) Load web pages Using requests library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSTnjmzDOhCv"
      },
      "source": [
        "r = requests.get(\"https://en.wikipedia.org/wiki/That_Darn_Cat_(1997_film)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cn6TZmKO86D"
      },
      "source": [
        "3) Convert web page to BeautifulSoup Object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8et7PJEpPIoj"
      },
      "source": [
        "soup = bs(r.content)\n",
        "def clean_tags(soup):\n",
        "  for tag in soup.find_all([\"sup\",\"span\"]):\n",
        "    tag.decompose() \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FizxnmTbQpaL"
      },
      "source": [
        "4) Grapping HTML Objects to deal with its to extract a data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soGxwFl_QoUl"
      },
      "source": [
        "# we use find method to grap HTML object by Selectors \n",
        "# find()：Gets the first tag of the incoming HTML object that satisfies the condition and returns. A function of a label group or a single label.\n",
        "# findAll()：Get all the conditions of the incoming HTML object and return it. Prototype: findAll(tag, atributes, recursive, text, limit, keywords)\n",
        "\n",
        "infoBox = soup.find(class_=\"infobox vevent\")\n",
        "infoRows = infoBox.find_all(\"tr\")\n",
        "clean_tags(soup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24e5Lg2oXUvV"
      },
      "source": [
        "Now I can access to all data in box info \n",
        "\n",
        "Now I need to extract data in form filmee name (title) and their data and stored it in python dictionary \n",
        "\n",
        "`I use Python enumerate() to  adds counter to an iterable and returns it (the enumerate object).`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC88L-GiYNx8"
      },
      "source": [
        "movieInfo = { }\n",
        "\n",
        "# get_Conteent_Value to loop in any itam have a list of names and out it in form list not text \n",
        "\n",
        "def get_Content_Value(rowData):\n",
        "  if rowData.find(\"li\"):\n",
        "    return [li.get_text(\" \",strip=True).replace(\"\\xa0\",\" \")  for li in rowData.find_all(\"li\")] \n",
        "    \n",
        "  elif rowData.find(\"br\"):\n",
        "        return [text for text in rowData.stripped_strings]\n",
        "  else:\n",
        "    return rowData.get_text(\" \",strip=True).replace(\"\\xa0\",\" \")\n",
        "\n",
        "for index , row in enumerate(infoRows):\n",
        "  if index == 0 :\n",
        "    movieInfo[\"title\"] = row.find(\"th\").get_text(\" \",strip=True)\n",
        "  elif index == 1:\n",
        "    continue\n",
        "  else:\n",
        "    contentKey= row.find(\"th\").get_text(\" \",strip=True)\n",
        "    contentValue= get_Content_Value(row.find(\"td\"))\n",
        "    movieInfo[contentKey] = contentValue\n",
        "\n",
        "for key , value in movieInfo.items():\n",
        "  print(f\"{key} : {value}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbzPyfj_lS6G"
      },
      "source": [
        "# **Task #2 Get info box for all films**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTlE59-JoNZg"
      },
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "\n",
        "def get_Content_Value(rowData):\n",
        "    if rowData.find(\"li\"):\n",
        "      return [li.get_text(\" \",strip=True).replace(\"\\xa0\",\" \")  for li in rowData.find_all(\"li\")] \n",
        "\n",
        "    elif rowData.find(\"br\"):\n",
        "        return [text for text in rowData.stripped_strings]\n",
        "    \n",
        "    else:\n",
        "      return rowData.get_text(\" \",strip=True).replace(\"\\xa0\",\" \")\n",
        "\n",
        "def clean_tags(soup):\n",
        "  for tag in soup.find_all([\"sup\",\"span\"]):\n",
        "    tag.decompose()\n",
        "\n",
        "def get_All_Films(fullPath):\n",
        "  r = requests.get(fullPath)\n",
        "  soup = bs(r.content)\n",
        "\n",
        "  infoBox = soup.find(class_=\"infobox vevent\")\n",
        "  infoRows = infoBox.find_all(\"tr\")\n",
        "  clean_tags(soup)\n",
        "  \n",
        "  movieInfo = {}\n",
        "\n",
        "  for index , row in enumerate(infoRows):\n",
        "    if index == 0 :\n",
        "      movieInfo[\"title\"] = row.find(\"th\").get_text(\" \",strip=True)\n",
        "    \n",
        "    else:\n",
        "      header = row.find('th')\n",
        "      if header:\n",
        "        contentKey= row.find(\"th\").get_text(\" \",strip=True)\n",
        "        contentValue= get_Content_Value(row.find(\"td\"))\n",
        "        movieInfo[contentKey] = contentValue\n",
        "  \n",
        "  return movieInfo\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5dptfZHTPCG"
      },
      "source": [
        "allreq = requests.get(\"https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films\")\n",
        "soup2 = bs(allreq.content)\n",
        "filmTables = soup2.select(\".wikitable.sortable i a\")\n",
        "\n",
        "basePath = \"https://en.wikipedia.org/\"\n",
        "\n",
        "movieList = [ ]\n",
        "for index , movie in enumerate(filmTables):\n",
        "  # if index == 2:\n",
        "  #   break\n",
        "  # if index % 10 == 0:\n",
        "  #   print(index)\n",
        "\n",
        "  try:\n",
        "    relativePath = movie[\"href\"]\n",
        "    fullPath = basePath + relativePath\n",
        "    title = movie[\"title\"]\n",
        "    movieList.append(get_All_Films(fullPath))\n",
        "  \n",
        "  except Exception as e:\n",
        "      print(movie.get_text())\n",
        "      print(e)\n",
        "\n",
        "# print(movieList)\n",
        "print(len(movieList()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHIp-Td0xSqm"
      },
      "source": [
        "# **Now we are going to save data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7yO_XcxXJmQ"
      },
      "source": [
        "import json\n",
        "def save(title,data):\n",
        "  with open(title,\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump(data,f,ensure_ascii=False,indent=3)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4ZSdjPfyoCS"
      },
      "source": [
        "def load(title):\n",
        "  with open(title,encoding=\"utf-8\") as f:\n",
        "    return json.load(f)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAN0NHBNMus5"
      },
      "source": [
        "save(\"Disney Data clean.json\",movieList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIn70giobXec"
      },
      "source": [
        "# **Task #3 Clean Our Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHAyHGZrbwoR"
      },
      "source": [
        "movieList = load(\"Disney Data clean.json\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygzbgWmZcrdQ"
      },
      "source": [
        "## **Sub-Tasks:** \n",
        "\n",
        "1) Clean up references [1]\n",
        "\n",
        "2) Convert running time into intger\n",
        "\n",
        "3) Conver datas int datetime object\n",
        "\n",
        "4) split up long string \n",
        "\n",
        "5) Convert budget & box office into numerical values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "donxnpnpc6lV"
      },
      "source": [
        "# Clean up references [1]\n",
        "# we go to clean it from html by its specific tag with decompose() for deleted it and extract()\n",
        "\n",
        "def clean_tags(soup):\n",
        "  for tag in soup.find_all([\"sup\",\"span\"]):\n",
        "    tag.decompose()\n",
        "\n",
        "# we put this function after creating soup object fron html page to temove this tage from html page before extract data \n",
        "# sup tag form reference\n",
        "#span to remove data like this (1999-10-12)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eliTL_aWm6tB"
      },
      "source": [
        "# split up long string \n",
        "\n",
        "\n",
        "# i am use thtis block of code on data get from html page to check if \"br\" found \n",
        "# between string to stripped it and return the blocks of string in list format \n",
        "# in this code we use list comprehension\n",
        "# We can now identify where list comprehensions are used.\n",
        "# the data return is a string, not a list. This is the power of list comprehension. \n",
        "# It can identify when it receives a string or a tuple and work on it like a list.\n",
        "#  syntax [expression for item in list]\n",
        "# expersion same the item \n",
        "\n",
        "elif rowData.find(\"br\"):\n",
        "        return [text for text in rowData.stripped_strings]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPCPwGyZtAK0"
      },
      "source": [
        "# Convert running time into intger\n",
        "#access to all moive running time and because it is a string we use list comprehension \n",
        "print([movie.get(\"Running time\", \"N/A\") for movie in movieList])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQHj_6WZvzef"
      },
      "source": [
        "def minutes_To_Int(runningTime):\n",
        "  if runningTime == \"N/A\":   # running time  N/A\n",
        "    return None\n",
        "  if isinstance(runningTime,list):  # running time  LIST\n",
        "    return int(runningTime[0].split(\" \")[0])\n",
        "  else:                                   ## running time  STRING        \n",
        "    return int(runningTime.split(\" \")[0])\n",
        "\n",
        "for movie in movieList:\n",
        "  movie[\"Running time\"] = minutes_To_Int(movie.get(\"Running time\",\"N/A\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT0ItQMl7zxH"
      },
      "source": [
        "# Convert budget & box office into numerical values\n",
        "# as Running time part \n",
        "\n",
        "[movie.get(\"Budget\" ,\"N/A\") for movie in movieList]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NboiAZt5G2M0"
      },
      "source": [
        "import re\n",
        "\n",
        "amounts = r\"thousand|million|billion\"\n",
        "number = r\"\\d+(,\\d{3})*\\.*\\d*\"\n",
        "\n",
        "word_re = rf\"\\${number}(-|\\sto\\s|–)?({number})?\\s({amounts})\"\n",
        "value_re = rf\"\\${number}\"\n",
        "\n",
        "def word_to_value(word):\n",
        "    value_dict = {\"thousand\": 1000, \"million\": 1000000, \"billion\": 1000000000}\n",
        "    return value_dict[word]\n",
        "\n",
        "def parse_word_syntax(string):\n",
        "    value_string = re.search(number, string).group()\n",
        "    value = float(value_string.replace(\",\", \"\"))\n",
        "    word = re.search(amounts, string, flags=re.I).group().lower()\n",
        "    word_value = word_to_value(word)\n",
        "    return value*word_value\n",
        "\n",
        "\n",
        "def parse_value_syntax(string):\n",
        "    value_string = re.search(number, string).group()\n",
        "    value = float(value_string.replace(\",\", \"\"))\n",
        "    return value\n",
        "\n",
        "def money_conversion(money):\n",
        "    if money == \"N/A\":\n",
        "        return None\n",
        "\n",
        "    if isinstance(money, list):\n",
        "        money = money[0]\n",
        "\n",
        "    word_syntax = re.search(word_re, money, flags=re.I)\n",
        "    value_syntax = re.search(value_re, money)\n",
        "\n",
        "    if word_syntax:\n",
        "        return parse_word_syntax(word_syntax.group())\n",
        "\n",
        "    elif value_syntax:\n",
        "        return parse_value_syntax(value_syntax.group())\n",
        "    \n",
        "    else:\n",
        "      return None"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aU3dg7mHqMg"
      },
      "source": [
        "for movie in movieList:\n",
        "  movie[\"Budget (float)\"] = money_conversion(movie.get(\"Budget\",\"N/A\"))\n",
        "  movie[\"Box office (float)\"] = money_conversion(movie.get(\"Box office\",\"N/A\"))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTj5TbGBKESI"
      },
      "source": [
        "# Convert datas int datetime object\n",
        "print([movie.get(\"Release date\",\"N\\A\") for movie in movieList])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV23hsBhLerJ"
      },
      "source": [
        "# june 26, 1950\n",
        "from datetime import datetime\n",
        "\n",
        "dates = [movie.get(\"Release date\",\"N/A\") for movie in movieList]\n",
        "def clean_date(date):\n",
        "  return date.split(\"(\")[0].strip()\n",
        "\n",
        "def date_conversion(date):\n",
        "    if isinstance(date, list):\n",
        "        date = date[0]\n",
        "    if date == \"N/A\":\n",
        "      return None\n",
        "        \n",
        "    dateStr = clean_date(date)\n",
        "    fmts = [\"%B %d, %Y\", \"%d %B %Y\"]\n",
        "    for fmt in fmts:\n",
        "        try:\n",
        "            return datetime.strptime(dateStr, fmt)\n",
        "        except:\n",
        "            pass\n",
        "    return None"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VorOxy_mOYDM"
      },
      "source": [
        "for movie in movieList:\n",
        "  movie[\"Release date (datetime)\"] = date_conversion(movie.get(\"Release date\",\"N/A\"))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLhr1HVQWRQU"
      },
      "source": [
        "import pickle\n",
        "\n",
        "def save_data_pickle(name, data):\n",
        "    with open(name, 'wb') as f:\n",
        "        pickle.dump(data, f)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDO7DwH3XzkO"
      },
      "source": [
        "def load_data_pickle(name):\n",
        "    with open(name, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2bEXoT9X2Qf"
      },
      "source": [
        "save_data_pickle(\"disney_movie_data_cleaned_more.pickle\", movieList)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlX5quVcXOQn"
      },
      "source": [
        "a = load_data_pickle(\"disney_movie_data_cleaned_more.pickle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0_9DAVbYUMA"
      },
      "source": [
        "a == movieList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US2qlBfiYdOp"
      },
      "source": [
        "# **Task #4 Attach IMDB /Rotten tomato Scores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOau2yXwa3JO"
      },
      "source": [
        "# http://www.omdbapi.com/?apikey=[yourkey]&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQbXKOlFat-x"
      },
      "source": [
        "import requests\n",
        "import urllib\n",
        "import os\n",
        "def get_omdb_info(title):\n",
        "  api_key = \"af390a9\"\n",
        "  base_url = \"http://www.omdbapi.com/?\"\n",
        "  parameters = {\"apikey\" : \"af390a9\" , 't': title}\n",
        "  params_encoded = urllib.parse.urlencode(parameters)\n",
        "  full_url = base_url + params_encoded\n",
        "  return requests.get(full_url).json()\n",
        "\n",
        "def get_rotten_tomato_score(omdb_info):\n",
        "  ratings = omdb_info.get('Ratings', [])\n",
        "  for rating in ratings:\n",
        "    if rating['Source'] == 'Rotten Tomatoes':\n",
        "      return rating['Value']\n",
        "  return None\n",
        "\n",
        "get_omdb_info(\"into the woods\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHxswfoAcQmd"
      },
      "source": [
        "for movie in movieList:\n",
        "    title = movie['title']\n",
        "    omdb_info = get_omdb_info(title)\n",
        "    movie['imdb'] = omdb_info.get('imdbRating', None)\n",
        "    movie['metascore'] = omdb_info.get('Metascore', None)\n",
        "    movie['rotten_tomatoes'] = get_rotten_tomato_score(omdb_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjIzzRkllDc_"
      },
      "source": [
        "# **Task #6 Save data in CSV and json file** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppjQmaFOlP3m"
      },
      "source": [
        "movieList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQzAmEiCln0w"
      },
      "source": [
        "movieListCopy = [movie.copy() for movie in movieList]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dLQ1weTlXII"
      },
      "source": [
        "for movie in movieListCopy:\n",
        "    currentDate = movie['Release date (datetime)']\n",
        "    if currentDate:\n",
        "        movie['Release date (datetime)'] = currentDate.strftime(\"%B %d, %Y\")\n",
        "    else:\n",
        "        movie['Release date (datetime)'] = None\n",
        "    "
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWXcbOhxlg0j"
      },
      "source": [
        "save(\"disney_data_final.json\", movieListCopy)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCzfLAIHmMTi"
      },
      "source": [
        "#Convert data to CSV\n",
        "\n",
        "import pandas as pd \n",
        "df = pd.DataFrame(movieList)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IS05JFimepO"
      },
      "source": [
        "df.to_csv(\"disney_movie_data_final.csv\")"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-EvGKManUsH"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE6_l-WemhIJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUqhb_84mq9Z"
      },
      "source": [
        "boxOffice = df.sort_values(['Box office (float)'],  ascending=False)\n",
        "boxOffice.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}