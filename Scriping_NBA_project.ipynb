{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scriping_NBA_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vwnQzeEQnXX6",
        "PQpEwiEHqz6S",
        "R9SeJSIQry5g",
        "lLgd53bjsyvr",
        "0bk304f8oTUm"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOkYdYeBk1dluZS49+X/Mu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhamedezzat/Pyhthon-Applications/blob/master/Scriping_NBA_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwnQzeEQnXX6"
      },
      "source": [
        "# **Task #1** \n",
        "\n",
        "## Get Data to one player only "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKQEDLK8Jbjz"
      },
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqDwX4z-NJXL"
      },
      "source": [
        "# make request to interested web page \n",
        "req = requests.get(\"https://www.nba.com/player/1628443/kadeem-allen\")\n",
        "# convert interested web page into BS object to extract the data\n",
        "soup = bs(req.content)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k0q_NpyO3nb"
      },
      "source": [
        "#get player team and number \n",
        "# team = soup.find(\"p\",class_=\"t11 md:t2\")\n",
        "# team= team.get_text()\n",
        "\n",
        "# to get played  full name \n",
        "name = soup.find_all(\"p\",class_=\"PlayerSummary_playerNameText__K7ZXO\")\n",
        "full_name = []\n",
        "\n",
        "for x in name:\n",
        "  full_name.append(x.get_text())\n",
        "full_name = \" \".join(full_name)\n",
        "\n",
        "total_personal_info = {}\n",
        "total_personal_info[\"name\"] = full_name\n",
        "total_personal_info [\"team\"] = team"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgWXMm0cSHbn"
      },
      "source": [
        "# to get player stat \n",
        " \n",
        "stat = soup.find(\"div\",class_=\"flex justify-center py-3 lg:justify-between lg:py-0\")\n",
        "info_label = stat.find_all(\"p\",class_=\"PlayerSummary_playerStatLabel__2f2Z8\")\n",
        "info_value = stat.find_all('p',class_=\"PlayerSummary_playerStatValue__3hvQY\")\n",
        "label = [ ]\n",
        "for x in info_label:\n",
        "  label.append(x.get_text())\n",
        "value = [ ]\n",
        "for y in info_value:\n",
        "  value.append(y.get_text())\n",
        "\n",
        "information = { }\n",
        "for a , b in zip(label,value):\n",
        "  information[a]= b\n",
        "\n",
        "# get player information \n",
        "\n",
        "info2 = soup.find(\"div\",class_=\"flex-col flex-grow hidden sm:flex\")\n",
        "\n",
        "info_label2 = info2.find_all(\"p\",class_=\"PlayerSummary_playerInfoLabel__gBXXP\")\n",
        "info_value2 = info2.find_all('p',class_=\"PlayerSummary_playerInfoValue__mSfou\")\n",
        "\n",
        "label2 = [ ]\n",
        "for x in info_label2:\n",
        "  label2.append(x.get_text())\n",
        "value2 = [ ]\n",
        "for y in info_value2:\n",
        "  value2.append(y.get_text())\n",
        "\n",
        "information2 = { }\n",
        "for a , b in zip(label2,value2):\n",
        "  information2[a]= b"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARzEBok7g2wd"
      },
      "source": [
        "# gathering Data\n",
        "all_information = {**total_personal_info,**information,**information2}\n",
        "# print(all_information)\n",
        "all_information=list(all_information)\n",
        "\n",
        "# Save one player data\n",
        "import pandas as pd \n",
        "df = pd.DataFrame(all_information)\n",
        "df.to_csv(\"all_information.csv\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DImMmh4MjJ2W"
      },
      "source": [
        "import json\n",
        "\n",
        "def save(title,data):\n",
        "  with open(title,\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump(data,f,ensure_ascii=False,indent=3)\n",
        "\n",
        "def load(title):\n",
        "  with open(title,encoding=\"utf-8\") as f:\n",
        "    return json.load(f)\n",
        "\n",
        "save(\"NBA.json\",fulldata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc_YZTTlvhMi"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.DataFrame(fulldata)\n",
        "df.to_csv(\"NBA Data Fin2al.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5osa2bddvr4e"
      },
      "source": [
        "df.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQpEwiEHqz6S"
      },
      "source": [
        "# **Task #2** \n",
        "\n",
        "## Extract Data from json file to get player Id and  player Name to make full url to pass this url to main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkilRJ46Rafa"
      },
      "source": [
        "import json\n",
        "response = requests.get(\"https://www.nba.com/players\")\n",
        "soup = bs(response.content)\n",
        "\n",
        "scripts = soup.find_all('script')[7].text.strip()[9756:304767]\n",
        "# scripts = soup.find_all('script')[7].text\n",
        "data = scripts.replace(\"'\", '\"')\n",
        "final_data = json.loads(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZGFm0R1xxv"
      },
      "source": [
        "# Save Json Data\n",
        "import json\n",
        "import codecs\n",
        "with open('jsonformatter.json', encoding='utf-8-sig') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "# Save Json data in CSV file\n",
        "import pandas as pd \n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"NBA Data Final.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9SeJSIQry5g"
      },
      "source": [
        "# **Task #3** \n",
        "\n",
        "## Extract player Id& Name from Json file and upload it in Csv file then covert it into list to loop through it to produce all urls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7r06idohNoH"
      },
      "source": [
        "# upload Json data in Csv file\n",
        "import pandas as pd\n",
        "df = pd.read_csv('players id&names.csv', delimiter=',')\n",
        "\n",
        "#Convert DF columns into lists \n",
        "list_of_id = df['PERSON_ID'].to_list()\n",
        "list_of_names = df['PLAYER_SLUG'].to_list()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDWiezcplwjJ"
      },
      "source": [
        "# Get all urls to pass it to main function \n",
        "\n",
        "all_url = [ ]\n",
        "base_url = \"https://www.nba.com/player/\"\n",
        "for id , name in zip (list_of_id , list_of_names):\n",
        "  url = base_url+str(id)+\"/\"+name\n",
        "  all_url.append(url)\n",
        "  \n",
        "urls = all_url\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATCp3219mt7B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLgd53bjsyvr"
      },
      "source": [
        "# **Task #4** \n",
        "\n",
        "## Pass all urls to the main function to Extract needed data from each player web page "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7BQChcttJJl"
      },
      "source": [
        "def all_played_data(full_url):\n",
        "\n",
        "  req = requests.get(full_url)\n",
        "  soup = bs(req.content)\n",
        "  #get player team and number \n",
        "  team = soup.find(\"p\",class_=\"t11 md:t2\")\n",
        "  if team is None:\n",
        "    team = \"N/A\"\n",
        "  else:\n",
        "    team = team.get_text()\n",
        "  #to get played  full name \n",
        "  name = soup.find_all(\"p\",class_=\"PlayerSummary_playerNameText__K7ZXO\")\n",
        "  full_name = []\n",
        "  for x in name:\n",
        "    full_name.append(x.get_text())\n",
        "  full_name = \" \".join(full_name)\n",
        "\n",
        "  total_personal_info = {}\n",
        "  total_personal_info[\"name\"] = full_name\n",
        "  total_personal_info [\"team\"] = team\n",
        "\n",
        "  # to get player stat \n",
        " \n",
        "  stat = soup.find(\"div\",class_=\"flex justify-center py-3 lg:justify-between lg:py-0\")\n",
        "  info_label = stat.find_all(\"p\",class_=\"PlayerSummary_playerStatLabel__2f2Z8\")\n",
        "  info_value = stat.find_all('p',class_=\"PlayerSummary_playerStatValue__3hvQY\")\n",
        "  label = [ ]\n",
        "  for x in info_label:\n",
        "    label.append(x.get_text())\n",
        "  value = [ ]\n",
        "  for y in info_value:\n",
        "    value.append(y.get_text())\n",
        "\n",
        "  information = { }\n",
        "  for a , b in zip(label,value):\n",
        "    information[a]= b\n",
        "\n",
        "  # get player information\n",
        "\n",
        "  info2 = soup.find(\"div\",class_=\"flex-col flex-grow hidden sm:flex\")\n",
        "\n",
        "  info_label2 = info2.find_all(\"p\",class_=\"PlayerSummary_playerInfoLabel__gBXXP\")\n",
        "  info_value2 = info2.find_all('p',class_=\"PlayerSummary_playerInfoValue__mSfou\")\n",
        "\n",
        "  label2 = [ ]\n",
        "  for x in info_label2:\n",
        "    label2.append(x.get_text())\n",
        "  value2 = [ ]\n",
        "  for y in info_value2:\n",
        "    value2.append(y.get_text())\n",
        "\n",
        "  information2 = { }\n",
        "  for a , b in zip(label2,value2):\n",
        "    information2[a]= b\n",
        "  all_information = {**total_personal_info,**information,**information2}\n",
        "  return all_information\n",
        "\n",
        "\n",
        "fulldata = [ ] \n",
        "for i in urls:\n",
        "  str(i)\n",
        "  print(i)\n",
        "  if i == \"https://www.nba.com/player/1629007/jontay-porter\" or i == \"https://www.nba.com/player/1629685/dylan-windler\" or i == \"https://www.nba.com/player/1629624/kenny-wooten\":\n",
        "    pass\n",
        "\n",
        "  else:\n",
        "    fulldata.append(all_played_data(i))\n",
        "\n",
        "print(fulldata)\n",
        "print(len(fulldata))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bk304f8oTUm"
      },
      "source": [
        "#**Task #5** \n",
        "\n",
        "## Save Data in Json and Csv files "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfe5mpH0oKaH"
      },
      "source": [
        "# Save data in Json file \n",
        "import json\n",
        "\n",
        "def save(title,data):\n",
        "  with open(title,\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump(data,f,ensure_ascii=False,indent=3)\n",
        "\n",
        "def load(title):\n",
        "  with open(title,encoding=\"utf-8\") as f:\n",
        "    return json.load(f)\n",
        "\n",
        "save(\"NBA Data.json\",fulldata)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFD7CyO4oqyH"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.DataFrame(fulldata)\n",
        "df.to_csv(\"NBA Data.csv\")"
      ],
      "execution_count": 95,
      "outputs": []
    }
  ]
}